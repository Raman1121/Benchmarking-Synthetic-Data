apiVersion: batch/v1
kind: Job
metadata:
  # NOTE: Replace ${USER}, ${JOB_SUFFIX}, and ${QUEUE_NAME} with your actual values
  #       or ensure they are properly substituted by your deployment mechanism.
  generateName: ${USER}-job-train-${JOB_SUFFIX}
  labels:
    eidf/user: ${USER}
    kueue.x-k8s.io/queue-name: ${QUEUE_NAME}
    kueue.x-k8s.io/priority-class: batch-workload-priority
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  backoffLimit: 0
  activeDeadlineSeconds: 864000
  ttlSecondsAfterFinished: 2592000
  template:
    metadata:
      labels:
        eidf/user: ${USER}
    spec:
      restartPolicy: OnFailure
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                      # - NVIDIA-H200
                      - NVIDIA-A100-SXM4-80GB
      tolerations:
        - key: "eidf098"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
        - key: "eidf107"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
      containers:
        - name: pytorch-cuda11-7 
          image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel
          workingDir: "/workspace/Benchmarking-Synthetic-Data"
          env:
            # --- START ADDITION ---
            - name: TZ
              value: "Etc/UTC"
            # --- END ADDITION ---
            - name: DEBIAN_FRONTEND # Keep this one too!
              value: "noninteractive"
            - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
              value: "1"
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_IB_DISABLE
              value: "1"
            # NOTE: Replace ${MAX_DELTA} if needed, or ensure it's substituted
            - name: MAX_DELTA
              value: "${MAX_DELTA}"
            - name: NCCL_IB_HCA
              value: "^mlx5"
            - name: PYTHONPATH
              value: "/workspace/Benchmarking-Synthetic-Data"
          command: ["/bin/bash", "-c"]
          args:
            - |
              set -e # Exit immediately if a command exits with a non-zero status.
              set -x # Print commands and their arguments as they are executed.

              echo "Updating apt and installing base packages..."
              apt update && apt install -y --no-install-recommends \
                  wget \
                  git \
                  unzip \
                  zip \
                  libgl1 \
                  libglib2.0-0 \
                  ffmpeg \
                  tzdata \
                  cmake

              echo "Installing git-all..."
              apt install -y --no-install-recommends git-all

              echo "Copying project files to writable PVC..."
              # Ensure target directory exists in PVC if necessary
              mkdir -p /pvc/Benchmarking-Synthetic-Data
              cp -r /workspace/Benchmarking-Synthetic-Data/* /pvc/Benchmarking-Synthetic-Data/
              cd /pvc/Benchmarking-Synthetic-Data

              echo "Cleaning up apt cache..."
              rm -rf /var/lib/apt/lists/*

              echo "Setting up Python environment..."
              python3 -m pip install --upgrade pip setuptools wheel
              echo "Installing environment dependencies..."
              pip install wavedrom
              python3 -m pip install --user lit
              pip install xtermcolor
              pip install termcolor
              pip install pandas

              echo "Installing LLaVA-Rad..."
              cd Downstream_Training/LLaVA-Rad
              export PYTHONPATH=$PYTHONPATH:/pvc/Benchmarking-Synthetic-Data/Downstream_Training/LLaVA-Rad/ # Corrected path
              pip install --upgrade pip # Often good practice before installs
              pip install -e .

              pip install tensorboardX

              echo "Installing Ninja..."
              pip -vvv install ninja > /pvc/ninja_install.log 2>&1
              ninja --version
              echo "Installing flash-attn with high verbosity..."
              MAX_JOBS=4  pip install -vvv flash-attn==2.5.8 --no-build-isolation > /pvc/flash_attn_install.log 2>&1 || { echo 'flash-attn install failed, check log'; cat /pvc/flash_attn_install.log; exit 1; }
              echo "flash-attn install command finished." 

              ############# Pre-Training Step (Alignment) #############
              # echo "Beginning pre-training..."
              # chmod +x scripts/pretrain.sh
              # bash scripts/pretrain.sh > logs_llavarad_pretraining.txt 2>&1

              ############# LoRA Fine-Tuning Step #############
              echo "Beginning training..."
              # Make sure the script exists at this path inside the PVC copy
              chmod +x scripts/finetune_lora_synthetic_data.sh
              bash scripts/finetune_lora_synthetic_data.sh > logs_llavarad_training.txt 2>&1
              echo "Training script finished."

              # echo "Running EVAL!!!"
              # chmod +x ./scripts/eval.sh
              # ./scripts/eval.sh > error_log.txt 2>&1
              # echo "Running EVAL done!!!"

              # echo "Calculating Results and Metrics!"
              # mv mimic_cxr_preds.jsonl llava/eval/rrg_eval/mimic_cxr_preds.jsonl
              # cd llava/eval/rrg_eval
              # python run.py mimic_cxr_preds.jsonl > eval_logs.txt 2>&1
              # echo "Results and metrics calculation done!"

              sleep 1000

          resources:
            limits:
              nvidia.com/gpu: "1"
              cpu: "8" # Might need more CPU depending on data loading/preprocessing
              memory: "96Gi" # Ensure this is sufficient
          volumeMounts:
            - name: workspace # Mount read-only if code isn't modified?
              mountPath: /workspace
              # readOnly: true # Consider if source code shouldn't be changed
            - name: writeable
              mountPath: /pvc
            - name: dshm
              mountPath: /dev/shm
      volumes:
        - name: workspace
          nfs:
            # Ensure NFS server and path are correct
            server: 10.24.6.77
            path: /user/s2198939-eidf107
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi # Ensure this is large enough for multiprocessing/shm needs
        - name: writeable
          persistentVolumeClaim:
            # Ensure this PVC exists and is bound in the correct namespace
            claimName: mimic-cxr2 # Make sure this matches your PVC name