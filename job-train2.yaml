apiVersion: batch/v1
kind: Job
metadata:
  generateName: ${USER}-job-train-${JOB_SUFFIX}
  labels:
    eidf/user: ${USER}
    kueue.x-k8s.io/queue-name: ${QUEUE_NAME}
    kueue.x-k8s.io/priority-class: batch-workload-priority
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  backoffLimit: 2147483647
  activeDeadlineSeconds: 864000
  template:
    metadata:
      labels:
        eidf/user: ${USER}
    spec:
      restartPolicy: OnFailure
      # Replace nodeSelector with affinity to allow multiple GPU types.
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                      - NVIDIA-H200
      # Add tolerations to allow scheduling on nodes with specific taints.
      tolerations:
        - key: "eidf098"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
        - key: "eidf107"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
      containers:
        - name: test2
          image: raman07/myapp:latest  # Ensure CUDA version matches host drivers
          workingDir: "/workspace/Benchmarking-Synthetic-Data"
          env:
            - name: TORCH_NCCL_ASYNC_ERROR_HANDLING
              value: "1"
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_IB_DISABLE
              value: "1"
            - name: MAX_DELTA
              value: "${MAX_DELTA}"
            - name: NCCL_IB_HCA
              value: "^mlx5"
            - name: PYTHONPATH
              value: "/workspace/Benchmarking-Synthetic-Data"
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Setting up environment..."
              export PYTHONPATH=$PYTHONPATH:/workspace/Benchmarking-Synthetic-Data
              python3 -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

              echo "Creating conda env"
              cd /pvc/ 
              mkdir -p miniconda3
              wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda3/miniconda.sh
              chmod +x miniconda3/miniconda.sh
              bash miniconda3/miniconda.sh -b -u -p miniconda3
              rm miniconda3/miniconda.sh

              echo "Creating conda env"
              /pvc/miniconda3/bin/conda init bash
              source /pvc/miniconda3/bin/activate
              conda activate sana || conda create -n sana python=3.8 -y && conda activate sana

              echo "Creating env for LLaVA-Rad"
              cd Downstream_Training/LLaVA-Rad
              pip install -e .

              echo "Installing flash-attn"
              pip install ninja
              pip install flash-attn --no-build-isolation

              sleep(10000)

              ./scripts/eval.sh
          resources:
            limits:
              nvidia.com/gpu: "1"
              cpu: "4"
              memory: "32Gi"
          volumeMounts:
            - name: nfs-user-107
              mountPath: /nfs-user-107
            - name: writeable
              mountPath: /pvc
            - name: dshm
              mountPath: /dev/shm
      volumes:
        - name: nfs-user-107
          nfs:
            server: 10.24.6.77
            path: /user/s2198939-eidf107
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
        - name: writeable
          persistentVolumeClaim:
            claimName: mimic-cxr2